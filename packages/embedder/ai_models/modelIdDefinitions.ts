import type {EmbeddingModelParams} from './AbstractEmbeddingsModel'

const qwen3Languages = [
  'af',
  'am',
  'ar',
  'as',
  'az',
  'be',
  'bg',
  'bn',
  'bo',
  'bs',
  'ca',
  'cs',
  'cy',
  'da',
  'de',
  'el',
  'en',
  'es',
  'et',
  'eu',
  'fa',
  'fi',
  'fo',
  'fr',
  'ga',
  'gd',
  'gl',
  'gu',
  'he',
  'hi',
  'hr',
  'ht',
  'hu',
  'hy',
  'id',
  'is',
  'it',
  'ja',
  'jv',
  'ka',
  'kk',
  'km',
  'kn',
  'ko',
  'lo',
  'lt',
  'lv',
  'mk',
  'ml',
  'mn',
  'mr',
  'ms',
  'mt',
  'my',
  'nb',
  'ne',
  'nl',
  'nn',
  'or',
  'pa',
  'pl',
  'ps',
  'pt',
  'ro',
  'ru',
  'sd',
  'si',
  'sk',
  'sl',
  'sq',
  'sr',
  'su',
  'sv',
  'sw',
  'ta',
  'te',
  'tg',
  'th',
  'tl',
  'tr',
  'tt',
  'uk',
  'ur',
  'uz',
  'vi',
  'zh'
] as const
export const modelIdDefinitions = {
  'BAAI/bge-large-en-v1.5': {
    embeddingDimensions: 1024,
    precision: 32,
    tableSuffix: 'bge_l_en_1p5',
    languages: ['en']
  },
  'llmrails/ember-v1': {
    embeddingDimensions: 1024,
    precision: 32,
    tableSuffix: 'ember_1',
    languages: ['en']
  },
  'Svenni551/Qwen3-Embedding-0.6B-ONNX-INT8': {
    embeddingDimensions: 1024,
    precision: 16,
    // Actual max is 32768, but we half that because attention = seqlen**2, so RAM will go up 4x
    // Also, since we're using this for embeddings, we want chunks to have more meaning. No soup.
    tableSuffix: 'qwen3v2',
    languages: qwen3Languages
  },
  'Qwen/Qwen3-Embedding-0.6B': {
    embeddingDimensions: 1024,
    precision: 16,
    // Actual max is 32768, but we half that because attention = seqlen**2, so RAM will go up 4x
    // Also, since we're using this for embeddings, we want chunks to have more meaning. No soup.
    tableSuffix: 'qwen3_600M',
    languages: qwen3Languages
  }
} satisfies Record<string, EmbeddingModelParams>

export type ModelId = keyof typeof modelIdDefinitions
